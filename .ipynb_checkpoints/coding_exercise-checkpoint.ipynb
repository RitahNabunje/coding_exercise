{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "s_pneumoniae_genomes/14412_3#82.contigs_velvet.fa: 1780322 kmers\n",
      "s_pneumoniae_genomes/14412_3#84.contigs_velvet.fa: 1770662 kmers\n",
      "s_pneumoniae_genomes/R6.fa: 1952351 kmers\n",
      "s_pneumoniae_genomes/TIGR4.fa: 2027930 kmers\n"
     ]
    }
   ],
   "source": [
    "#----------Task one : Reading k-mers--------------------------\n",
    "# import the required modules\n",
    "from Bio import SeqIO # to handle sequences\n",
    "from collections import defaultdict # for the kmer collections\n",
    "\n",
    "# Step 1: Write code to read in the DNA sequence from the above FASTA files,\n",
    "# and count the occurences of 14-mers in each of the four files\n",
    "# (storing these in a dictionary or similar).\n",
    "\n",
    "# example - making kmers from a sequence\n",
    "seq = \"TTGAAAGAAAAACAATTTTG\"\n",
    "k_dict = defaultdict(int) # empty dict\n",
    "for idx in range(0, len(seq) - 13): # last kmer starts at the 14th nt\n",
    "    kmer = seq[idx:(idx + 14)]\n",
    "    if kmer in k_dict: # increase count of kmer exists in the dict\n",
    "        k_dict[kmer] = k_dict.get(kmer, 0) + 1\n",
    "    else:\n",
    "        k_dict[kmer] = 1 # add kmer as key to the dict\n",
    "print(len(k_dict))\n",
    "\n",
    "# function to count the kmers from a fasta file\n",
    "def count_kmers_from_fasta(fasta_file, k):\n",
    "    # read the input file\n",
    "    fasta_entry = SeqIO.parse(open(fasta_file), 'fasta')\n",
    "    # make empty dict\n",
    "    kmers_dict = defaultdict(int)\n",
    "    # read each contig separately\n",
    "    for contig in fasta_entry:\n",
    "        sequence = str(contig.seq)\n",
    "        # obtain kmers across the contig seq\n",
    "        for idx in range(0, len(sequence) - (k - 1)):  # last kmer is the last k nt in the sequence\n",
    "            kmer = sequence[idx:(idx + k)]\n",
    "            # store kmers to a dict if doesn't already exist, but increase count if it already exists\n",
    "            if kmer in kmers_dict:\n",
    "                kmers_dict[kmer] = kmers_dict.get(kmer, 0) + 1\n",
    "            else:\n",
    "                kmers_dict[kmer] = 1\n",
    "    # count the occurences of kmers the file\n",
    "    return f'{fasta_file}: {len(kmers_dict)} kmers'\n",
    "\n",
    "\n",
    "# count the occurences of 14-mers in each of the four files\n",
    "files = (\"s_pneumoniae_genomes/14412_3#82.contigs_velvet.fa\",\n",
    "         \"s_pneumoniae_genomes/14412_3#84.contigs_velvet.fa\",\n",
    "         \"s_pneumoniae_genomes/R6.fa\", \"s_pneumoniae_genomes/TIGR4.fa\")\n",
    "for file in files:\n",
    "    print(count_kmers_from_fasta(file, 14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnB: 5, AuB: 9\n",
      "jaccard index : 0.5555555555555556\n",
      "jaccard distance: 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "# ---------------Task two : Simple Jaccard distances --------------------\n",
    "# calculate the Jaccard distance between two of the input samples\n",
    "# example of two kmer lists\n",
    "\n",
    "A = [\"TTGAAAGAAAAACA\", \"TGAAAGAAAAACAA\",\n",
    "     \"GAAAGAAAAACAAT\", \"AAAGAAAAACAATT\",\n",
    "     \"AAGAAAAACAATTT\", \"AGAAAAACAATTTT\", \n",
    "     \"GAAAAACAATTTTG\"]\n",
    "B = [\"TTGAAAGAAAAACA\", \"TGAAAGAAAAACAA\", \n",
    "     \"GAAAGAAAAACAAT\", \"AAAGAAAAACAATT\",\n",
    "     \"GAAAAACAATTTTG\", \"CTCGATCCATGTAT\", \n",
    "     \"TCGATCCATGTATG\"]\n",
    "# could compare the lists but let's first make dicts as in the first example\n",
    "# first make empty dicts, then add the kmers\n",
    "dictA = defaultdict(int)\n",
    "for kmer in A:\n",
    "    # check if kmer is already in the dict\n",
    "    if kmer in dictA:\n",
    "        dictA[kmer] = dictA.get(kmer, 0)+1 # just increase the value count if already exists\n",
    "    else:\n",
    "        dictA[kmer] = 1 # add it if it doesn't\n",
    "\n",
    "dictB = defaultdict(int)\n",
    "for kmer in B:\n",
    "    # check if kmer is already in the dict\n",
    "    if kmer in dictB:\n",
    "        dictB[kmer] = dictB.get(kmer, 0)+1 # just increase the value count if already exists\n",
    "    else:\n",
    "        dictB[kmer] = 1 # add it if it doesn't\n",
    "        \n",
    "# count shared and unique kmers between samples\n",
    "AnB, AuB = 0, 0 # initiate count as 0 for both intersection and union\n",
    "for k in dictA: # compare all A against B\n",
    "    if k in dictB: # if shared between the two\n",
    "        AnB += 1 # increase intersection count\n",
    "        AuB += 1 # increase the union as well\n",
    "        del dictB[k] # remove the shared kmer from the dict\n",
    "    else:\n",
    "        AuB += 1 # it is unique to A, so add it the union\n",
    "# the remains in B are unique to B, add them to the union as well\n",
    "AuB += len(dictB)\n",
    "print(f'AnB: {AnB}, AuB: {AuB}')\n",
    "\n",
    "# calculate the jaccard index\n",
    "j_index = AnB/AuB\n",
    "print(f'jaccard index : {j_index}')\n",
    "\n",
    "# calculate the jaccard distance\n",
    "j_dist = 1-j_index\n",
    "print(f'jaccard distance: {j_dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard index : 0.43923666207454476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jaccard Distance : 0.5607633379254553'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the Jaccard distance between two of the input samples\n",
    "# on the sample files\n",
    "# i like to use functions\n",
    "def fasta_to_kmers(fasta, k_value):\n",
    "    fasta_entry = SeqIO.parse(open(fasta), 'fasta')\n",
    "    kmers_dict = defaultdict(int)\n",
    "    # treat each contig as separate\n",
    "    for contig in fasta_entry:\n",
    "        sequence = str(contig.seq)\n",
    "        # obtain kmers across the contig\n",
    "        for idx in range(0, len(sequence) - (k_value - 1)):  # last kmer is the last k nt in the sequence\n",
    "            kmer = sequence[idx:(idx + k_value)]\n",
    "            # store kmers to a dict if doesn't already exist, but increase count if it already exists\n",
    "            if kmer in kmers_dict:\n",
    "                kmers_dict[kmer] = kmers_dict.get(kmer, 0) + 1\n",
    "            else:\n",
    "                kmers_dict[kmer] = 1\n",
    "    return kmers_dict\n",
    "\n",
    "\n",
    "def cal_jaccard_distance(fasta1, fasta2, k):\n",
    "    # read the input files and obtain kmers\n",
    "    kmers_dictA = fasta_to_kmers(fasta1, k)\n",
    "    kmers_dictB = fasta_to_kmers(fasta2, k)\n",
    "\n",
    "    # count shared and unique kmers between samples\n",
    "    AnB, AuB = 0, 0\n",
    "    for kmer in kmers_dictA:\n",
    "        if kmer in kmers_dictB:  # shared kmers between the two samples\n",
    "            AnB += 1\n",
    "            AuB += 1\n",
    "            del kmers_dictB[kmer]  # remove the shared kmer from the B dict\n",
    "        else:  # unique kmers from A\n",
    "            AuB += 1\n",
    "    # add the unique kmers in B to the union\n",
    "    AuB += len(kmers_dictB)\n",
    "\n",
    "    # calculate the jaccard index\n",
    "    j_index = AnB / AuB\n",
    "    print(f'jaccard index : {j_index}')\n",
    "\n",
    "    # calculate the jaccard distance\n",
    "    j_dist = 1 - j_index\n",
    "    #     print(f'jaccard distance: {j_dist}')\n",
    "    return f'Jaccard Distance : {j_dist}'\n",
    "\n",
    "\n",
    "cal_jaccard_distance(\"s_pneumoniae_genomes/14412_3#82.contigs_velvet.fa\",\n",
    "                     \"s_pneumoniae_genomes/14412_3#84.contigs_velvet.fa\", 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard index : 0.02563124048040474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jaccard Distance : 0.9743687595195952'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_jaccard_distance(\"s_pneumoniae_genomes/R6.fa\", \"s_pneumoniae_genomes/TIGR4.fa\", 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ad3bb24\n"
     ]
    }
   ],
   "source": [
    "# -------------------- MinHash Jaccard distances ------------------------\n",
    "# Step 3: Find an implementation of a hash function and import it into your code.\n",
    "# Calculate the hash of some example 14-mers, and confirm that the same 14-mer input maps to the same integer output.\n",
    "import xxhash\n",
    "\n",
    "# some 14-mers for this example\n",
    "kmers = [\"TTGAAAGAAAAACA\", \"TGAAAGAAAAACAA\", \"GAAAGAAAAACAAT\",\n",
    "         \"AAAGAAAAACAATT\", \"AAGAAAAACAATTT\", \"AGAAAAACAATTTT\",\n",
    "         \"GAAAAACAATTTTG\"]\n",
    "# calculate a hash of the first k-mer, this comes back as a hex string.\n",
    "print(xxhash.xxh32(kmers[0]).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3ad3bb24', 'dc529a4b', '45fab9d4', '2d857675', '055d3d72', 'c3967606', 'e864aa15']\n"
     ]
    }
   ],
   "source": [
    "# Run on all the k-mers\n",
    "hash1 = []\n",
    "for kmer in kmers:\n",
    "    hash1.append(xxhash.xxh32(kmer).hexdigest())\n",
    "print(hash1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Confirm the same hashes are generated on repeated runs (so they are comparable between samples)\n",
    "hash2 =[]\n",
    "for kmer in kmers:\n",
    "    hash2.append(xxhash.xxh32(kmer).hexdigest())\n",
    "print(hash2 == hash1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Make a sketch of each of the input sequences by following the steps above:\n",
    "# mapping any present 14-mers (ignoring their actual count as before)\n",
    "# to integers using a hash function, then taking the lowest 1000 values and storing these in a list/array.\n",
    "# Save your sketches for each input sequence: either as a text file, or some other representation.\n",
    "\n",
    "# get dictionary of kmers\n",
    "dict82 = fasta_to_kmers(\"s_pneumoniae_genomes/14412_3#82.contigs_velvet.fa\", 14)\n",
    "dict84 = fasta_to_kmers(\"s_pneumoniae_genomes/14412_3#84.contigs_velvet.fa\", 14)\n",
    "\n",
    "\n",
    "# make hashes for the kmers\n",
    "def dict_hashes(the_dict):\n",
    "    result = []\n",
    "    for key in the_dict:\n",
    "        result.append(xxhash.xxh32(key).hexdigest())\n",
    "    return result\n",
    "\n",
    "\n",
    "# loop through the files\n",
    "files = (\"s_pneumoniae_genomes/14412_3#82.contigs_velvet.fa\", \"s_pneumoniae_genomes/14412_3#84.contigs_velvet.fa\")\n",
    "for file in files:\n",
    "    dict_file = fasta_to_kmers(file, 14) # use previous function to get kmers from the fasta\n",
    "    hashes = dict_hashes(dict_file) # get hashes for the kmers using the function\n",
    "    sorted_hashes = sorted(hashes) # sort the hashes\n",
    "    s = 1000\n",
    "    smallest = sorted_hashes[0:1000] # get the smallest 1000 hashes\n",
    "    # save the smallest hashes to a text file\n",
    "    text = open(f'{file[0:-3]}_1000smallest_hashes', \"w\") # name text file accordingly\n",
    "    for elt in smallest:\n",
    "        text.write(elt + \"\\n\")\n",
    "    text.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard index : 0.44613159797541574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5538684020245843"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: For each pair of inputs, load their sketches, and\n",
    "# calculate their Jaccard distance using the sizes of the intersection and the union of the saved hash values.\n",
    "# load their sketches\n",
    "# calculate their Jaccard distance using the sizes of the intersection and the union of the saved hash values\n",
    "\n",
    "\n",
    "# function to calculate haccard distance from a sketch of hashes\n",
    "def cal_hashes_jaccard_distance(sketch1, sketch2):\n",
    "    # read the input files for the hashes\n",
    "    sketchA = open(sketch1, \"r\")\n",
    "    sketchB = open(sketch2, \"r\")\n",
    "    Ahashes = sketchA.readlines()\n",
    "    Bhashes = sketchB.readlines()\n",
    "\n",
    "    # count shared and unique hashes between the two inputs\n",
    "    AnB, AuB = 0, 0\n",
    "    for hsh in Ahashes:\n",
    "        if hsh in Bhashes:  # shared hashes between the two inputs\n",
    "            AnB += 1\n",
    "            AuB += 1\n",
    "            Bhashes.remove(hsh)  # remove the shared hash from B \n",
    "        else:  # unique hashes from A\n",
    "            AuB += 1\n",
    "    # add the unique (those that remained) hashes in B to the union\n",
    "    AuB += len(Bhashes)\n",
    "\n",
    "    # calculate the jaccard index\n",
    "    j_index = AnB / AuB\n",
    "    print(f'jaccard index : {j_index}')\n",
    "\n",
    "    # calculate the jaccard distance\n",
    "    j_dist = 1 - j_index\n",
    "    #     print(f'jaccard distance: {j_dist}') \n",
    "    return j_dist\n",
    "\n",
    "\n",
    "cal_hashes_jaccard_distance(\"s_pneumoniae_genomes/14412_3#82.contigs_velvet_1000smallest_hashes\",\n",
    "                            \"s_pneumoniae_genomes/14412_3#84.contigs_velvet_1000smallest_hashes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
